# ğŸ’» Bayesian Neural Net
The following notebooks contain code for creating basic Bayesian Neural Networks.
## ğŸ‘¨â€ğŸ’» Code
The notebooks are divided in sections, including: 
1) Theory overview
2) Code snippets with commentaries
   * Networks setup
   * Data setup
   * Training
   * Evaluating
## ğŸ“ˆ Models used
### â™Ÿ Net architecture
Two small models are implemented in every notebook with one architecture utilizing Multi-Layer Perceptrons and the second one with
convolutional layers.
### ğŸ² Bayesian inference
To approximate posterior distribution, two methods of approximating were used:
1) Variational Inference
2) Markov Chain Monte Carlo
## ğŸ“š References
1) Python packages: PyTorch and Pyro 
2) L. V. Jospin, H. Laga, F. Boussaid, W. Buntine, and M. Bennamoun, "Hands-on bayesian neural networks - a tutorial for deep learning users"
3) M. Betancourt, "A conceptual introduction to hamiltonian monte carlo"
4) M. D. Hoffman, A. Gelman, et al., "The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo."
5) A. Gelman and D. B. Rubin, "Inference from iterative simulation using multiple sequences"
